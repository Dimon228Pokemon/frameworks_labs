# 1. Выбор начальных условий

## 1.a. Датасет для задачи классификации

Для задачи классификации выбран набор данных **UCI Credit Card Default Dataset**.

**Обоснование выбора:**
- Набор данных представляет реальную бизнес-задачу — прогноз дефолта клиента банка
- Датасет содержит разнообразные типы данных: числовые, категориальные, временные
- Присутствует реальная несбалансированность классов (default vs non-default), что делает задачу нетривиальной
- Датасет используется в реальных ML-проектах банков и финансовых организаций
- Размер выборки (30 000+ объектов) достаточно велик для качественного анализа и тестирования KNN

**Целевая переменная:** `default.payment.next.month` (0 - нет дефолта, 1 - дефолт)  
**Тип задачи:** бинарная классификация

## 1.b. Датасет для задачи регрессии

Для задачи регрессии выбран набор данных **London Property Listings Dataset**.

**Обоснование выбора:**
- Датасет представляет реальную задачу: прогноз стоимости недвижимости в Лондоне
- Содержит как числовые признаки (площадь, количество комнат, средняя цена района), так и категориальные (тип объекта, район, почтовый индекс)
- Реальная вариативность цен создаёт условия для обучения регрессионных моделей
- Размер датасета (29 000+ записей) позволяет надёжно обучать и тестировать KNN

**Целевая переменная:** `Price`  
**Тип задачи:** регрессия

## 1.c. Обоснование выбора метрик

### Для классификации
Используем:
- **Accuracy** - доля правильных предсказаний (базовая оценка)
- **Precision** - важно в задаче дефолтов: насколько качественно модель предсказывает рисковых клиентов
- **Recall** - доля найденных реальных дефолтов (критично для банков)
- **F1-score** - баланс precision и recall
- **ROC-AUC** - устойчивость модели при разных порогах классификации

**Вывод:** из-за дисбаланса классов основными метриками являются F1-score и ROC-AUC

### Для регрессии
Используем:
- **MAE** - средняя абсолютная ошибка, легко интерпретируется как ошибка в фунтах
- **RMSE** - показывает штраф за большие ошибки (важно при прогнозе дорогой недвижимости)
- **MSE** - удобна для сравнения моделей во время обучения
- **R^2** - доля объяснённой дисперсии; интерпретируемость результата

**Вывод:** основными метриками считаются MAE и R^2, как наиболее интерпретируемые для бизнеса

# 2. Создание бейзлайна и оценка качества

## 2.a. Обучение моделей sklearn

Были обучены базовые модели KNN:
- `KNeighborsClassifier(n_neighbors=5)`
- `KNeighborsRegressor(n_neighbors=5)`

Использованы стандартные гиперпараметры без подбора.  
Все данные были предварительно нормализованы (`StandardScaler`) и категориальные признаки преобразованы `OneHotEncoder`.

## 2.b. Оценка качества baseline моделей

### Классификация - baseline KNN

| Метрика    | Значение |
|------------|----------|
| Accuracy   | 0.793    |
| Precision  | 0.550    |
| Recall     | 0.356    |
| F1-score   | 0.432    |
| ROC-AUC    | 0.704    |

**Вывод:** F1 и ROC-AUC ниже желаемого уровня → baseline слабый

### Регрессия - baseline KNN

| Метрика | Значение |
|---------|----------|
| MAE     | 129 742  |
| RMSE    | 183 739  |
| R^2      | 0.892    |

**Вывод:** baseline хорош, но явно есть потенциал для улучшения

# 3. Улучшение бейзлайна

## 3.a. Сформулированные гипотезы

### Классификация
- Масштабирование числовых признаков улучшит KNN
- One-hot кодирование категориальных признаков улучшит качество
- Подбор гиперпараметров (k, p, weights) даст существенный прирост
- Фильтрация выбросов по сумме платежей (BILL_AMT) улучшит устойчивость модели

### Регрессия
- Очистка выбросов по Size, Bathrooms, Bedrooms, Price улучшит стабильность
- One-hot кодирование районов и почтовых индексов поможет учесть локацию
- Подбор гиперпараметров улучшит MAE и R^2

## 3.b. Проверка гипотез

Все гипотезы были экспериментально проверены:
- Улучшенные препроцессоры → улучшение результатов
- `GridSearchCV` дал оптимальные параметры:
  - классификация: `k=11`, `p=2`, `weights=uniform`
  - регрессия: `k=11`, `p=1`, `weights=distance`

## 3.c. Улучшенный бейзлайн

Модели:
- `KNeighborsClassifier(n_neighbors=11, p=2, weights='uniform')`
- `KNeighborsRegressor(n_neighbors=11, p=1, weights='distance')`

## 3.d - 3.e. Обучение и оценка улучшенных моделей

### Улучшенная классификация KNN

| Метрика    | Baseline | Improved |
|------------|----------|----------|
| F1         | 0.432    | 0.434    |
| ROC-AUC    | 0.704    | 0.726    |

### Улучшенная регрессия KNN

| Метрика | Baseline | Improved |
|---------|----------|----------|
| MAE     | 129 742  | 120 264  |
| R^2      | 0.892    | 0.905    |

## 3.f. Сравнение результатов

- В классификации улучшение небольшое - KNN чувствителен к размерности и дисбалансу
- В регрессии — улучшение значительное: MAE уменьшился примерно на 10 000 фунтов

## 3.g. Выводы

- KNN лучше работает в регрессии, чем в классификации
- Оптимизация расстояний и весов даёт значимый прирост качества
- Грамотный препроцессинг даёт заметный вклад

# 4. Имплементация алгоритма KNN вручную

## 4.a. Реализация

Реализованы две версии:
- `MyKNNClassifier` и `MyKNNRegressor` — базовый KNN
- `MyImprovedKNN…` - улучшенная модель:
  - метрика Минковского (p=1/2)
  - взвешивание расстояний 1/dist
  - подбор числа соседей

## 4.b - 4.c. Обучение и оценка

### Самописные модели показывают:

#### Регрессия — self-made KNN

| Метрика | Baseline | Improved |
|---------|----------|----------|
| MAE     | 143 974  | 135 572  |
| R^2      | 0.859    | 0.875    |

## 4.d. Сравнение self-made vs sklearn baseline

Скейлёрн версия лучше - оптимизация расстояний + реализация C.  
Но самописная улучшенная версия догоняет и повторяет улучшения гиперпараметров, что подтверждает корректность реализации.

## 4.e. Вывод

- Реализация KNN выполнена корректно
- Улучшенные методы дают более высокое качество
- Самописная версия подтверждает принципы работы sklearn KNN

## 4.f - 4.i. Улучшение self-made моделей

В самописные алгоритмы были внедрены:
- весовые коэффициенты соседей
- оптимальный p
- оптимальный k

**Результат:** Улучшенные self-made модели стали сопоставимы с улучшенными sklearn

## 4.j. Общий вывод

- Все этапы реализации KNN выполнены
- Проведено улучшение baseline и self-made моделей
- Результаты улучшились как в классификации, так и в регрессии
- Самописная реализация полностью валидирует понимание работы алгоритма