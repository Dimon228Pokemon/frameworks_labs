# Лабораторная работа №4
## Исследование модели Random Forest (классификация и регрессия)

---

# 2. Создание бейзлайна и оценка качества

## 2.a. Baseline модели sklearn

Были построены две базовые модели:
*   **RandomForestClassifier** для кредитного скоринга
*   **RandomForestRegressor** для прогнозирования цен недвижимости в Лондоне

**Подготовка данных перед обучением:**

**Классификация:**
*   Стандартизация числовых признаков (`StandardScaler`)
*   OHE-кодирование категорий (`OneHotEncoder`)
*   Стратифицированный train/test сплит (`stratify=y`)

**Регрессия:**
*   Категориальные признаки заменены на среднюю цену по категории
*   Train/test сплит без переработки

---

## 2.b. Качество baseline моделей

#### Классификация - Baseline RandomForestClassifier

| Метрика    | Значение |
|------------|----------|
| Accuracy   | 0.8133   |
| Precision  | 0.6349   |
| Recall     | 0.3670   |
| F1         | 0.4651   |
| ROC-AUC    | 0.7539   |

**Вывод:** модель неплохо работает на Accuracy, но Recall очень низкий - плохо ловит дефолтных клиентов (что критично в задаче).

#### Регрессия - Baseline RandomForestRegressor

| Метрика | Значение |
|---------|----------|
| MAE     | 113 219  |
| RMSE    | 154 180  |
| R^2      | 0.9242   |

**Вывод:** базовая модель даёт хорошее качество предсказаний, R^2 высокий, ошибки умеренные.

---

# 3. Улучшение бейзлайна

## 3.a. Сформулированные гипотезы

**Классификация:**
1.  Учёт дисбаланса классов через `class_weight='balanced'`
2.  Увеличение глубины леса
3.  Увеличение количества деревьев
4.  Подбор `min_samples_split` / `min_samples_leaf`

**Регрессия:**
1.  Увеличение количества деревьев до 1000+
2.  Ограничение глубины уменьшает переобучение
3.  Уменьшение `min_samples_leaf` возможно повысит точность
4.  Подбор `max_features` ("sqrt" / "log2")

---

## 3.b. Проверка гипотез (GridSearchCV)

**RandomForestClassifier - лучшие параметры:**
```python
{
  "class_weight": "balanced",
  "max_depth": 9,
  "min_samples_leaf": 1,
  "min_samples_split": 2,
  "n_estimators": 100
}
```

**RandomForestRegressor - лучшие параметры:**
```python
{
 'reg__max_depth': 20,
 'reg__max_features': 'sqrt',
 'reg__min_samples_leaf': 1,
 'reg__n_estimators': 1000
}
```
## 3.c. Улучшенный бейзлайн

Используются найденные гиперпараметры.

## 3.d - 3.e. Оценка улучшенных моделей

### Классификация - Improved RandomForestClassifier

| Метрика     | Baseline | Improved |
|-------------|----------|----------|
| Accuracy    | 0.8133   | 0.7882   |
| Precision   | 0.6349   | 0.5193   |
| Recall      | 0.3670   | **0.5682** |
| F1          | 0.4651   | **0.5426** |
| ROC-AUC     | 0.7539   | **0.7754** |

**Вывод:** Recall и F1 выросли заметно - улучшенная модель лучше находит “плохих” клиентов. Accuracy упал, что нормально при росте Recall.

### Регрессия - Improved RandomForestRegressor

| Метрика | Baseline | Improved |
|---------|----------|----------|
| MAE     | 113 219  | **112 416** |
| RMSE    | 154 180  | **152 559** |
| R^2      | 0.9242   | **0.9258** |

**Вывод:** улучшенные параметры дали небольшой, но стабильный прирост качества.

## 3.f. Сравнение результатов

- **Классификация:** улучшения значимые - Recall +57%, F1 выше.
- **Регрессия:** улучшение небольшое, но модель стала стабильнее.

---

# 4. Имплементация алгоритмов вручную

## 4.a. Самописные модели

Реализованы:

- `SimpleDecisionTreeClassifier`
- `MyRandomForestClassifier`
- `MyDecisionTreeRegressor`
- `MyRandomForestRegressor`

Обе модели включают:

- собственный bootstrap
- bagging по признакам
- поиск лучшего сплита
- построение дерева в виде рекурсивной структуры

## 4.b - 4.c. Оценка самописных моделей

### Классификация - самописный RandomForest

**Baseline (ручная модель)**

| Метрика     | Значение |
|-------------|----------|
| Accuracy    | 0.8040   |
| Precision   | 0.6422   |
| Recall      | 0.2570   |
| F1          | 0.3671   |
| ROC-AUC     | 0.6082   |

**Improved (ручная модель)**

| Метрика     | Значение |
|-------------|----------|
| Accuracy    | **0.8130** |
| Precision   | **0.6717** |
| Recall      | **0.3022** |
| F1          | **0.4168** |
| ROC-AUC     | **0.6301** |

**Вывод:** улучшенная версия стала более сбалансированной (F1, ROC-AUC), но всё ещё значительно уступает sklearn.

### Регрессия - самописный RandomForestRegressor

| Модель      | MAE      | RMSE     | R^2       |
|-------------|----------|----------|----------|
| Baseline    | 224 198  | 319 868  | 0.6739   |
| Improved    | **219 021** | **310 643** | **0.6924** |

**Вывод:** улучшенный вариант немного улучшает качество, но всё равно сильно проигрывает sklearn (что логично - нет оптимизаций, нет параллелизации, нет продвинутого поиска сплитов).

## 4.d. Сравнение самописных моделей и sklearn

**Классификация**

- sklearn обучается значительно лучше (в 1.5-2 раза по главной метрике F1)
- самописная модель всё же воспроизводит тренды улучшения

**Регрессия**

- sklearn даёт R^2 = 0.925, самописная =0.69 - плюс 25% по объяснённой дисперсии
- самописная модель сильно упрощена, но работает корректно

## 4.e. Итоговые выводы

1. Улучшенный `RandomForestClassifier` значительно повышает Recall и F1, что важно для задачи кредитного скоринга.
2. Улучшенный `RandomForestRegressor` даёт небольшое, но стабильное улучшение качества.
3. Реализованные вручную алгоритмы работают корректно и повторяют тенденции sklearn, но сильно уступают по качеству - что ожидаемо без оптимизаций библиотеки.
4. Улучшенный самописный RandomForest показывает рост качества в обеих задачах, что подтверждает правильность реализованных механизмов bagging + feature subsampling.

---

## Финальная сравнительная таблица (классификация + регрессия)

### Классификация

| Metric      | sklearn baseline | sklearn improved | my baseline | my improved |
|-------------|------------------|------------------|-------------|-------------|
| Accuracy    | 0.8133           | 0.7882           | 0.8040      | **0.8130**  |
| Precision   | 0.6349           | 0.5193           | 0.6422      | **0.6717**  |
| Recall      | 0.3670           | **0.5682**       | 0.2570      | 0.3022      |
| F1          | 0.4651           | **0.5426**       | 0.3671      | 0.4168      |
| ROC-AUC     | 0.7539           | **0.7754**       | 0.6082      | 0.6301      |

### Регрессия

| model              | MAE      | RMSE     | R^2       |
|--------------------|----------|----------|----------|
| sklearn baseline   | 113 219  | 154 180  | 0.9242   |
| sklearn improved   | **112 416**  | **152 559**  | **0.9258**   |
| my baseline        | 224 198  | 319 868  | 0.6739   |
| my improved        | **219 021**  | **310 643**  | **0.6924**   |
