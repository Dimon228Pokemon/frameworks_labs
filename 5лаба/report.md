## 2. Создание бейзлайна и оценка качества
### 2.a. Baseline модели sklearn
Построены две базовые модели:
*   **GradientBoostingClassifier** - задача кредитного скоринга
*   **GradientBoostingRegressor** - прогноз стоимости недвижимости

**Подготовка данных**

*   **Классификация:**
    *   Стандартизация числовых признаков (StandardScaler)
    *   OHE-кодирование категориальных (OneHotEncoder)
    *   Стратифицированный train/test (stratify=y)

*   **Регрессия:**
    *   Категориальные признаки кодируются через OHE
    *   Train/test сплит без дополнительных преобразований

### 2.b. Качество baseline моделей

**Классификация - Baseline GradientBoostingClassifier**

| Метрика   | Значение |
|-----------|----------|
| Accuracy  | 0.8195   |
| Precision | 0.6699   |
| Recall    | 0.3625   |
| F1        | 0.4704   |
| ROC-AUC   | 0.7790   |

**Вывод:** Модель хорошо работает по Accuracy и ROC-AUC, но Recall низкий - плохо ловит дефолтных клиентов.

**Регрессия - Baseline GradientBoostingRegressor**

| Метрика | Значение |
|---------|----------|
| MAE     | 128 105  |
| RMSE    | 163 470  |
| R²      | 0.9148   |

**Вывод:** базовая модель даёт высокое качество, но есть возможность улучшения через Feature Engineering.

## 3. Улучшение бейзлайна
### 3.a. Сформулированные гипотезы

*   **Классификация:**
    1.  Добавить агрегированные признаки: `TOTAL_BILL`, `TOTAL_PAY`, `MEAN_PAY`, `MAX_PAY`
    2.  Нормализовать распределения через лог-преобразования `log(PAY_AMT*)`
    3.  Учесть дисбаланс через `sample_weight`
    4.  Подобрать гиперпараметры (`n_estimators`, `max_depth`, `subsample`, `min_samples_leaf`)

*   **Регрессия:**
    1.  Добавить новые признаки: `Size_per_Bedroom`, `Postcode_freq`, `BedBath`, `Area_Rank`
    2.  Применить логарифмирование таргета (`Price_log`)
    3.  Разделить задачу на cheap / luxury сегменты (роутер)
    4.  Подобрать глубину и число деревьев

### 3.b. Проверка гипотез

*   **Классификация:**
    1.  Новые признаки систематически улучшают Recall.
    2.  Лог-трансформации `PAY_AMT` стабилизируют распределения.
    3.  Весовые коэффициенты усиливают вклад класса "1" и повышают Recall.
    4.  Подбор гиперпараметров дал оптимальный набор:
        *   `n_estimators = 514`
        *   `max_depth = 4`
        *   `min_samples_leaf = 23`
        *   `learning_rate = 0.1`
        *   `subsample = 0.6`

*   **Регрессия:**
    1.  FE уменьшает смещение и снижает MAE.
    2.  Лог-таргет улучшает R² на ~0.015.
    3.  Модель-роутер повышает качество в верхнем ценовом сегменте.
    4.  Лучшие параметры: `n_estimators ≈ 200–400`, `max_depth=3`.

### 3.c. Улучшенный бейзлайн

*   **Классификация - Improved GB v2**
    *   Использует: FE, log-преобразования, `sample_weight`, оптимальные гиперпараметры.
*   **Регрессия - Improved GB**
    *   Использует: FE, логирование таргета, роутер, tuned GB модели.

### 3.d - 3.e. Оценка улучшенных моделей

**Классификация - Improved Gradient Boosting**

| Метрика   | Baseline | Improved |
|-----------|----------|----------|
| Accuracy  | 0.8195   | 0.7537   |
| Precision | 0.6699   | 0.4575   |
| Recall    | 0.3625   | 0.6119   |
| F1        | 0.4704   | 0.5235   |
| ROC-AUC   | 0.7790   | 0.7665   |

**Вывод:** Улучшенная модель резко повышает Recall (+69%) и F1. Это важно в задаче скоринга.

**Тюнинг порога (threshold)**
Перебрали 50 порогов, лучшая F1 при:
*   Порог: 0.5408
*   F1: 0.5283

**Метрики после оптимального порога:**

| Метрика   | Значение |
|-----------|----------|
| Accuracy  | 0.7690   |
| Precision | 0.4817   |
| Recall    | 0.5848   |
| F1        | 0.5283   |
| ROC-AUC   | 0.7665   |

**Регрессия - Improved Gradient Boosting**

| Метрика | Baseline | Improved |
|---------|----------|----------|
| MAE     | 128 105  | 110 468  |
| RMSE    | 163 470  | 147 511  |
| R²      | 0.9148   | 0.9306   |

**Вывод:** FE + логирование + роутер дают ощутимое повышение качества.

### 3.f. Сравнение результатов

**Классификация**

| Модель                 | Accuracy | Precision | Recall | F1    | ROC-AUC |
|------------------------|----------|-----------|--------|-------|---------|
| Baseline GB            | 0.8195   | 0.6699    | 0.3625 | 0.4704| 0.7790  |
| Improved GB v2         | 0.7537   | 0.4575    | 0.6119 | 0.5235| 0.7665  |
| Improved + threshold   | 0.7690   | 0.4817    | 0.5848 | 0.5283| 0.7665  |

**Регрессия**

| Модель      | MAE     | RMSE    | R²     |
|-------------|---------|---------|--------|
| Baseline    | 128 105 | 163 470 | 0.9148 |
| Improved    | 110 468 | 147 511 | 0.9306 |

## 4. Имплементация алгоритмов вручную
### 4.a. Самописные модели
Реализованы:
*   `MyDecisionTreeRegressorFast` - дерево для бустинга (квантильные пороги)
*   `MyGradientBoostingClassifierFast` - собственная реализация GB для классификации
*   `SimpleTreeRegressor` - дерево для регрессии
*   `SimpleGBR` - остаточный бустинг (регрессия)

**Основные особенности:**
*   рекурсивные деревья
*   поиск лучшего сплита по снижению MSE
*   логит-инициализация (классификация)
*   сигмоида + отрицательный градиент

### 4.b - 4.c. Оценка самописных моделей

**Классификация - baseline self-implemented**

| Метрика   | Значение |
|-----------|----------|
| Accuracy  | 0.8182   |
| Precision | 0.6980   |
| Recall    | 0.3135   |
| F1        | 0.4327   |
| ROC-AUC   | 0.7476   |

**Классификация - improved self-implemented**

| Метрика   | Значение |
|-----------|----------|
| Accuracy  | 0.8178   |
| Precision | 0.6573   |
| Recall    | 0.3685   |
| F1        | 0.4722   |
| ROC-AUC   | 0.7792   |

**Регрессия - baseline SimpleGBR**

| Метрика | Значение |
|---------|----------|
| MAE     | 141 646  |
| RMSE    | 201 097  |
| R²      | 0.8711   |

**Регрессия - improved SimpleGBR**

| Метрика | Значение |
|---------|----------|
| MAE     | 126 373  |
| RMSE    | 168 884  |
| R²      | 0.9091   |

### 4.d. Сравнение самописных моделей и sklearn

*   **Классификация**
    *   Sklearn остаётся лучше по F1,
    *   но самописная улучшенная модель выходит на уровень ROC-AUC sklearn.

*   **Регрессия**
    *   Sklearn показывает R² = 0.93
    *   Самописная улучшенная - R² = 0.91
    *   Тренды полностью совпадают: улучшение FE → рост качества.

### 4.e. Итоговые выводы

1.  Улучшенный Gradient Boosting для классификации значительно увеличил Recall и F1.
2.  Для регрессии достижение R² 0.93 делает модель сильнее, чем в ЛР3–4.
3.  Самописная реализация повторяет поведение sklearn, что подтверждает корректность реализации.
4.  Улучшения FE оказались ключевыми как для классификации, так и для регрессии.