# Итоговый вывод по результатам всех лабораторных работ (1-5)

В ходе пяти лабораторных работ были изучены, реализованы и сравнены классические алгоритмы машинного обучения для задач классификации (прогноз дефолта клиента банка) и регрессии (прогноз стоимости недвижимости). Для каждого алгоритма были построены baseline-модели, проведён тюнинг гиперпараметров, выполнен feature engineering, а также реализованы собственные версии моделей с нуля.

## 1. Динамика качества классификации (кредитный скоринг)

Главная метрика - **F1-score** и **Recall**, поскольку критично предсказывать дефолтных клиентов.

### Итоговое сравнение по F1 (лучшие версии sklearn):

| Алгоритм                      | F1   | Recall      | ROC-AUC | Итог                                                                 |
|-------------------------------|------|-------------|---------|----------------------------------------------------------------------|
| KNN                           | 0.43| 0.35-0.40   | 0.72    | слабый результат, чувствителен к масштабированию                    |
| Logistic Regression (улучшенная) | 0.47 | **0.63**    | 0.71    | лучший recall среди “линейных” моделей                              |
| Decision Tree (улучшенная)    | 0.52 | 0.55        | 0.76    | сильный рост качества после ограничения глубины                     |
| Random Forest (улучшенная)    | **0.54** | 0.57        | **0.78**| стабильная и сбалансированная модель                                |
| Gradient Boosting (улучшенная)| 0.53–0.53 | 0.58–0.61   | 0.77    | лучший Recall, конкурент F1 (с оптимальным threshold)               |

### Вывод по классификации

*   **KNN** оказался наименее эффективным из-за многомерности данных и дисбаланса классов.
*   **Логистическая регрессия** существенно улучшается при добавлении regularization и `class_weight="balanced"`.
*   **Решающие деревья** сильно выигрывают от ограничения глубины.
*   **Random Forest** дал один из самых высоких F1 и стал самой устойчивой моделью.
*   **Gradient Boosting** после feature engineering и тюнинга дал лучший Recall, что важно для задач скоринга.

**Общий лидер по качеству классификации:**  
- **Random Forest / Gradient Boosting** (в зависимости от предпочтений: стабильность vs максимальный recall).

---

## 2. Динамика качества регрессии (прогноз стоимости жилья)

Основные метрики - **MAE** и **R^2**.

### Итоговое сравнение по регрессии (лучшие версии sklearn):

| Алгоритм                      | MAE     | R^2    | Итог                                                                 |
|-------------------------------|----------|--------|----------------------------------------------------------------------|
| KNN                           | 120k    | 0.905  | хорош, но сильно зависит от масштаба                                |
| Linear/Ridge Regression (улучшенная) | 126k | 0.916  | стабильная интерпретируемая модель                                  |
| Decision Tree (улучшенная)    | 127k     | 0.914  | улучшилось, но всё ещё склонно к переобучению                       |
| Random Forest (улучшенная)    | 112k     | 0.926  | высокий результат, устойчивость                                     |
| Gradient Boosting (улучшенная)| **110k** | **0.931**| **лучшая модель по всем метрикам**                                 |

### Вывод по регрессии

*   **Decision Tree** даёт сильное переобучение, если не ограничить глубину.
*   **KNN** и **Linear/Ridge** дают хорошие, но ограниченные результаты.
*   **Random Forest** заметно превосходит предыдущие алгоритмы.
*   **Gradient Boosting** стал самым точным алгоритмом, особенно после feature engineering (Size_per_Bedroom, Area_Rank, лог-таргет и др.).

**Общий лидер по регрессии:**  
- **Gradient Boosting**, с уверенным преимуществом по MAE и R^2.

---

## 3. Сравнение sklearn vs self-made реализаций

Во всех лабораторных работах собственные реализации:

*   повторяют тенденции sklearn-моделей,
*   корректно реагируют на улучшения (регуляризация, ограничения глубины, FE),
*   но уступают библиотечным версиям по качеству из-за отсутствия оптимизаций C-уровня и более примитивного поиска сплитов.

**Вывод:** самописные реализации полностью валидируют корректное понимание алгоритмов и их механизмов.

---

## 4. Общий итог по всем лабораторным работам

*   **KNN** - слабый результат, чувствителен к размерности и масштабу; годится только как baseline.
*   **Линейные модели** - слабее деревьев на нелинейных данных, но дают хороший recall после регуляризации.
*   **Решающие деревья** - сильный прирост качества после ограничения глубины.
*   **Random Forest** - лучший классический ансамбль: высокая стабильность, высокая точность.
*   **Gradient Boosting** - **лучшая модель во всём исследовании**, особенно для регрессии. В классификации благодаря threshold tuning и FE достигает лучшего Recall.

### Финальный вывод

**Gradient Boosting** стал лучшим алгоритмом в обеих задачах, обойдя все предыдущие модели.  
**Random Forest** занял второе место, оставаясь наиболее устойчивым и стабильным.  
Линейные модели и KNN оказались ограниченными на сложных и нелинейных датасетах.  
Самописные алгоритмы подтвердили корректность понимания и воспроизвели ключевые паттерны sklearn.

Такое комплексное сравнение демонстрирует, что ансамблевые модели - особенно **Gradient Boosting** - являются оптимальным выбором как для задач скоринга, так и для высокоточной регрессии цен недвижимости.